{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data_handler as dh\n",
    "import model as md\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "pd.options.mode.chained_assignment = None \n",
    "import copy\n",
    "from scipy.stats import norm\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(dh)\n",
    "importlib.reload(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba\n",
    "numba.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "from platform import python_version\n",
    "print('python', python_version())\n",
    "print('numpy', np.__version__)\n",
    "print('pandas', pd.__version__)\n",
    "import graph_tool\n",
    "print('graph_tool', graph_tool.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beckmann model\n",
    "\n",
    "parameter $\\mu = 0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beckmann_save = 'beckmann_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_name = 'Anaheim_net.tntp'\n",
    "trips_name = 'Anaheim_trips.tntp'\n",
    "\n",
    "handler = dh.DataHandler()\n",
    "graph_data = handler.GetGraphData(net_name, columns = ['init_node', 'term_node', 'capacity', 'free_flow_time'])\n",
    "graph_correspondences, total_od_flow = handler.GetGraphCorrespondences(trips_name)\n",
    "\n",
    "model = md.Model(graph_data, graph_correspondences, \n",
    "                    total_od_flow, mu = 0.25, rho = 0.15)\n",
    "\n",
    "graph_data['graph_table'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.logspace(3,-0.5,8)\n",
    "epsilons = [epsilons[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert(model.mu == 0.25)\n",
    "max_iter = 10000\n",
    "for index, eps_abs in enumerate(epsilons):\n",
    "    if index < len(epsilons) - 1:\n",
    "        continue\n",
    "    print('eps_abs =', eps_abs)\n",
    "    solver_kwargs = {'eps_abs': eps_abs,\n",
    "                     'max_iter': max_iter, 'stop_crit': 'dual_gap',\n",
    "                     'verbose' : True, 'verbose_step': 4000, 'save_history' : True}\n",
    "    tic = time.time()\n",
    "    result = model.find_equilibrium(solver_name = 'ustm', composite = True, solver_kwargs = solver_kwargs)\n",
    "    toc = time.time()\n",
    "    print('Elapsed time: {:.0f} sec'.format(toc - tic))\n",
    "    print('Time ratio =', np.max(result['times'] / graph_data['graph_table']['free_flow_time']))\n",
    "    print('Flow excess =', np.max(result['flows'] / graph_data['graph_table']['capacity']) - 1, end = '\\n\\n')\n",
    "\n",
    "    result['eps_abs'] = eps_abs\n",
    "    result['elapsed_time'] = toc - tic\n",
    "    with open(beckmann_save + 'anaheim_result_' + 'ustm' + '_eps_abs_' + str(index) + '_beckmann.pickle', 'wb') as f:\n",
    "        pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_result = result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_roads(graph_table, node):\n",
    "    return set(graph_table[np.array(graph_table['term_node'] == node) + np.array(graph_table['init_node'] == node)].index)\n",
    "\n",
    "\n",
    "def edge_neighbours(graph_table, edge_num):\n",
    "    init_node = graph_table.loc[edge_num]['init_node']\n",
    "    term_node = graph_table.loc[edge_num]['term_node']\n",
    "    res = node_roads(graph_table, init_node)\n",
    "    res.update(node_roads(graph_table, term_node))\n",
    "    return res\n",
    "\n",
    "def n_neighbour_edges(graph_table, node, depth):\n",
    "    neighbours = node_roads(graph_table, node)\n",
    "    for i in range(depth - 1):\n",
    "        new_neighbours = neighbours.copy()\n",
    "        for curr_edge in neighbours:\n",
    "            new_neighbours.update(edge_neighbours(graph_table, curr_edge))\n",
    "        neighbours = new_neighbours\n",
    "    return neighbours\n",
    "\n",
    "\n",
    "def normal_distribution_noise(graph_data, graph_correspondences, node, depth, std_percentage_capacity, std_percentage_flow):\n",
    "    graph_data_copy = copy.deepcopy(graph_data)\n",
    "    graph_correspondences_copy = copy.deepcopy(graph_correspondences)\n",
    "    graph_capacity = graph_data_copy['graph_table']['capacity']\n",
    "    graph_free_flow_time = graph_data_copy['graph_table']['free_flow_time']\n",
    "\n",
    "    graph_table = graph_data['graph_table']\n",
    "    neighbour_edges = n_neighbour_edges(graph_table, node, depth)\n",
    "\n",
    "    for index in neighbour_edges:\n",
    "        capacity = graph_capacity[index]\n",
    "        std = capacity * std_percentage_capacity\n",
    "        noise = norm.rvs(0, std)\n",
    "        graph_capacity[index] = capacity + noise\n",
    "\n",
    "        flow = graph_free_flow_time[index]\n",
    "        std = flow * std_percentage_flow\n",
    "        noise = norm.rvs(0, std)\n",
    "        graph_free_flow_time[index] = flow + noise\n",
    "    return graph_data_copy, graph_correspondences_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_percentage_capacity = 0.05\n",
    "std_percentage_flow = 0.05\n",
    "node = random.randint(1, graph_data['nodes number'])\n",
    "print(node)\n",
    "depth = 2\n",
    "new_graph_data, new_graph_correspondences = normal_distribution_noise(graph_data, graph_correspondences, node, depth, std_percentage_capacity, std_percentage_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = md.Model(new_graph_data, new_graph_correspondences, \n",
    "                    total_od_flow, mu = 0.25, rho = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(model.mu == 0.25)\n",
    "max_iter = 40000\n",
    "for index, eps_abs in enumerate(epsilons):\n",
    "    if index < len(epsilons) - 1:\n",
    "        continue\n",
    "    print('eps_abs =', eps_abs)\n",
    "    solver_kwargs = {'eps_abs': eps_abs,\n",
    "                     'max_iter': max_iter, 'stop_crit': 'dual_gap',\n",
    "                     'verbose' : True, 'verbose_step': 4000, 'save_history' : True}\n",
    "    tic = time.time()\n",
    "    result = new_model.find_equilibrium(t_start = old_result['times'],solver_name = 'ustm', composite = True, solver_kwargs = solver_kwargs)\n",
    "    toc = time.time()\n",
    "    print('Elapsed time: {:.0f} sec'.format(toc - tic))\n",
    "    print('Time ratio =', np.max(result['times'] / graph_data['graph_table']['free_flow_time']))\n",
    "    print('Flow excess =', np.max(result['flows'] / graph_data['graph_table']['capacity']) - 1, end = '\\n\\n')\n",
    "\n",
    "    result['eps_abs'] = eps_abs\n",
    "    result['elapsed_time'] = toc - tic\n",
    "    with open(beckmann_save + 'anaheim_result_' + 'ustm' + '_eps_abs_' + str(index) + '_beckmann.pickle', 'wb') as f:\n",
    "        pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
